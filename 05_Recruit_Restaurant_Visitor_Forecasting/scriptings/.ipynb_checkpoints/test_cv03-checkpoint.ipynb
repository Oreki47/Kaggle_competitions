{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "##### import sys\n",
    "import re\n",
    "import gc\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from general.preprocess import data_preparation\n",
    "from general.clf_wrappers import LgbWrapper\n",
    "from features.f0 import features_set_f0\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_store dataframe shape: (829, 57)\n"
     ]
    }
   ],
   "source": [
    "full_data, ntrain, ntest = data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (252108, 123) test data size: (32019, 123)\n"
     ]
    }
   ],
   "source": [
    "trn = full_data[:ntrain]\n",
    "tst = full_data[ntrain:]\n",
    "print('train data size:', trn.shape, 'test data size:', tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'visitors'\n",
    "FEATURES = features_set_f0()\n",
    "SEED = 177\n",
    "lgb_params = {}\n",
    "lgb_params['n_estimators'] = 50\n",
    "lgb_params['learning_rate'] = 0.1 # shrinkage_rate\n",
    "lgb_params['metric'] = 'l1'          # or 'mae'\n",
    "lgb_params['sub_feature'] = 0.34\n",
    "lgb_params['bagging_fraction'] = 0.85 # sub_row\n",
    "lgb_params['bagging_freq'] = 40\n",
    "lgb_params['num_leaves'] = 512        # num_leaf\n",
    "lgb_params['min_data'] = 500         # min_data_in_leaf\n",
    "lgb_params['min_hessian'] = 0.05     # min_sum_hessian_in_leaf\n",
    "lgb_params['verbose'] = 0\n",
    "lgb_params['feature_fraction_seed'] = 2\n",
    "lgb_params['bagging_seed'] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "\n",
    "def score_valid(y_true, y_valid):\n",
    "    score = np.sqrt(mean_squared_log_error(y_true, y_valid))\n",
    "    return score\n",
    "\n",
    "def get_store_ids():\n",
    "    df = pd.read_csv('../data/air_store_info.csv')\n",
    "    return df['air_store_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(full_data, clf, seed, ntrain, ntest, features, target, nfolds=5):\n",
    "    # define\n",
    "    lst_vld_date = pd.to_datetime('2017-4-22')  # one day before test\n",
    "    lst_v06_date = lst_vld_date - pd.DateOffset(days=38)\n",
    "    lst_v33_date = lst_vld_date - pd.DateOffset(days=32)   \n",
    "    step_by_days = 10\n",
    "   # folds\n",
    "    \n",
    "    # split train/valid\n",
    "    trn = full_data[:ntrain]\n",
    "    tst = full_data[ntrain:]\n",
    "    \n",
    "    # setup train on test\n",
    "    x_trn = trn[features].values\n",
    "    y_trn = trn[target].values\n",
    "    x_tst = tst[features].values\n",
    "    \n",
    "    # remove unnecessary data sets\n",
    "    del full_data\n",
    "    gc.collect()\n",
    "    \n",
    "    v06_scoring = np.zeros((nfolds,))\n",
    "    v33_scoring = np.zeros((nfolds,))\n",
    "    oof_tst = np.zeros((ntest,))\n",
    "    oof_tst_fld = np.empty((ntest, nfolds))\n",
    "    oof_score = [None] * 2\n",
    "\n",
    "    for i in range(nfolds):\n",
    "        # first date of each set\n",
    "        v06_date = lst_v06_date - pd.DateOffset(days=(nfolds-i-1)*step_by_days) \n",
    "        v33_date = lst_v33_date - pd.DateOffset(days=(nfolds-i-1)*step_by_days)\n",
    "\n",
    "        # setup train on valid\n",
    "        x_tvd = trn[trn.visit_date < v06_date][features].values\n",
    "        y_tvd = trn[trn.visit_date < v06_date][target].values\n",
    "        assert(x_tvd.shape[0] == y_tvd.shape[0])\n",
    "        \n",
    "        x_v06 = trn[trn.visit_date.between(v06_date, v33_date - pd.DateOffset(days=1))][features].values\n",
    "        y_v06 = trn[trn.visit_date.between(v06_date, v33_date - pd.DateOffset(days=1))][target].values\n",
    "        \n",
    "        x_v33 = trn[trn.visit_date.between(v33_date, v33_date + pd.DateOffset(days=32))][features].values\n",
    "        y_v33 = trn[trn.visit_date.between(v33_date, v33_date + pd.DateOffset(days=32))][target].values\n",
    "        # train on train_valid set and predict on v06/v33 set\n",
    "        clf.train(x_tvd, y_tvd)\n",
    "        v06_scoring[i] = score_valid(y_v06, clf.predict(x_v06))\n",
    "        v33_scoring[i] = score_valid(y_v33, clf.predict(x_v33))\n",
    "\n",
    "        # train on train_full set and predict on test\n",
    "        clf.train(x_trn, y_trn)\n",
    "        oof_tst_fld[:, i] = clf.predict(x_tst)\n",
    "\n",
    "        del x_tvd, y_tvd, x_v06, x_v33\n",
    "        gc.collect()\n",
    "    \n",
    "    oof_tst[:] = oof_tst_fld.mean(axis=1)\n",
    "    oof_score[0] = np.mean(v06_scoring)\n",
    "    oof_score[1] = np.mean(v33_scoring)\n",
    "\n",
    "    sub = tst[['id', target]]\n",
    "    sub[target] = oof_tst.reshape(-1, 1)\n",
    "    \n",
    "    v06 = None\n",
    "    v33 = None\n",
    "\n",
    "    return sub, v06, v33, oof_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "G:\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:60: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "lgb_clf= LgbWrapper(seed=SEED, params=lgb_params)\n",
    "results = cross_validate(\n",
    "    full_data=full_data,\n",
    "    clf=lgb_clf,\n",
    "    seed=SEED,\n",
    "    ntrain=ntrain,\n",
    "    ntest=ntest,\n",
    "    features=FEATURES,\n",
    "    target=TARGET,\n",
    "    nfolds=5,\n",
    ")\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.46617470884691, 0.48753824640516247]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
