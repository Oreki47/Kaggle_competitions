{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "from general.preprocess import data_preparation\n",
    "from general.clf_wrappers import LgbWrapper\n",
    "from features.f0 import features_set_f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_store dataframe shape: (829, 57)\n"
     ]
    }
   ],
   "source": [
    "full_data, ntrain, ntest = data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (252108, 123) test data size: (32019, 123)\n"
     ]
    }
   ],
   "source": [
    "trn = full_data[:ntrain]\n",
    "tst = full_data[ntrain:]\n",
    "print('train data size:', trn.shape, 'test data size:', tst.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = 'visitors'\n",
    "FEATURES = features_set_f0()\n",
    "SEED = 177\n",
    "\n",
    "lgb_params = {}\n",
    "lgb_params['objective'] = 'regression'\n",
    "lgb_params['metric'] = 'l2_root'\n",
    "lgb_params['n_jobs'] = -1\n",
    "lgb_params['learning_rate'] = 0.1 # shrinkage_rate\n",
    "lgb_params['random_state'] = 177\n",
    "lgb_params['n_estimators'] = 50\n",
    "\n",
    "lgb_params['num_leaves'] = 512 \n",
    "lgb_params['lambda_l1'] = 1\n",
    "lgb_params['lambda_l2'] = 1\n",
    "lgb_params['bagging_fraction'] = 0.85 # sub_row\n",
    "lgb_params['feature_fraction'] = 0.85\n",
    "lgb_params['bagging_freq'] = 3\n",
    "\n",
    "\n",
    "clf = LgbWrapper(seed=SEED, params=lgb_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_valid(y_true, y_valid):\n",
    "    score = np.sqrt(mean_squared_log_error(y_true, y_valid))\n",
    "    return score\n",
    "\n",
    "\n",
    "def oof_score_analysis():\n",
    "    '''\n",
    "        simple analysis of the oof_score and score in each folds\n",
    "    :return:\n",
    "    '''\n",
    "    return 0\n",
    "\n",
    "def get_store_ids():\n",
    "    df = pd.read_csv('../data/air_store_info.csv')\n",
    "    return df['air_store_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate(full_data, clf, seed, ntrain, ntest, features, target, nfolds=5):\n",
    "    # define\n",
    "    lst_vld_date = pd.to_datetime('2017-4-22')  # one day before test\n",
    "    v06_str = lst_vld_date - pd.DateOffset(days=38)\n",
    "    v33_str = lst_vld_date - pd.DateOffset(days=32)\n",
    "    \n",
    "    # setup a validation set from 3/15 -3/20 and 3/21 - 4/22.\n",
    "    trn = full_data[:ntrain]\n",
    "    tst = full_data[ntrain:]   \n",
    "    tvd = trn[trn.visit_date < v06_str]  # tvd: train set on valid set\n",
    "    v06 = trn[trn.visit_date.between(v06_str, v33_str - pd.DateOffset(days=1))]\n",
    "    v33 = trn[trn.visit_date.between(v33_str, lst_vld_date)]\n",
    "    \n",
    "    # assertions\n",
    "    assert(v33.visit_date.max() == lst_vld_date)\n",
    "    assert((v33.visit_date.min() - v06.visit_date.max()).days == 1)\n",
    "    assert((v06.visit_date.max() - v06.visit_date.min()).days == 5)\n",
    "    assert((v33.visit_date.max() - v33.visit_date.min()).days == 32)\n",
    "\n",
    "    oof_v06 = np.zeros((v06.shape[0],))\n",
    "    oof_v33 = np.zeros((v33.shape[0],))\n",
    "    oof_tst = np.zeros((ntest,))\n",
    "    oof_tst_fld = np.empty((ntest, nfolds))\n",
    "    oof_score = [None]*2\n",
    "    print('oof_v06 shape: ', oof_v06.shape, 'oof_v33 shape:', oof_v33.shape)\n",
    "    \n",
    "    # split stores\n",
    "    store_ids = get_store_ids()\n",
    "    folds = KFold(n_splits=nfolds, shuffle=True, random_state=seed).split(store_ids)\n",
    "\n",
    "    for i, ids in enumerate(folds):\n",
    "        # for predicting the test\n",
    "        trn_idx = trn.air_store_id.isin(store_ids[ids[0]])\n",
    "        \n",
    "        x_trn = trn[trn_idx][features].values\n",
    "        y_trn = trn[trn_idx][target].values\n",
    "        \n",
    "        x_tst = tst[features].values\n",
    "\n",
    "        # for predicting the valid\n",
    "        tvd_idx = tvd.air_store_id.isin(store_ids[ids[0]])\n",
    "        v06_idx = v06.air_store_id.isin(store_ids[ids[1]])\n",
    "        v33_idx = v33.air_store_id.isin(store_ids[ids[1]])\n",
    "        \n",
    "        x_tvd = tvd[tvd_idx][features].values\n",
    "        y_tvd = tvd[tvd_idx][target].values\n",
    "        \n",
    "        x_v06 = v06[v06_idx][features].values        \n",
    "        x_v33 = v33[v33_idx][features].values\n",
    "        \n",
    "        # train on train_valid set and predict on v06/v33 set\n",
    "        clf.train(x_tvd, y_tvd)\n",
    "        oof_v06[v06_idx] = clf.predict(x_v06)\n",
    "        oof_v33[v33_idx] = clf.predict(x_v33)   \n",
    "        \n",
    "        # train on train_full set and predict on test\n",
    "        clf.train(x_trn, y_trn)\n",
    "        oof_tst_fld[:, i] = clf.predict(x_tst)\n",
    "        \n",
    "        del x_trn, y_trn, x_tst, x_tvd, y_tvd, x_v06, x_v33\n",
    "        gc.collect()\n",
    "\n",
    "    oof_tst[:] = oof_tst_fld.mean(axis=1)\n",
    "    oof_score[0] = score_valid(v06[target].values, oof_v06)\n",
    "    oof_score[1] = score_valid(v33[target].values, oof_v33)\n",
    "\n",
    "    return oof_tst.reshape(-1, 1), oof_v06.reshape(-1, 1), oof_v33.reshape(-1, 1), oof_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "oof_v06 shape:  (1615,) oof_v33 shape: (8721,)\n"
     ]
    }
   ],
   "source": [
    "results = cross_validate(full_data, clf, SEED, ntrain, ntest, FEATURES, TARGET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.52541361, 0.4935467 ])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(results[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.47 0.48"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
