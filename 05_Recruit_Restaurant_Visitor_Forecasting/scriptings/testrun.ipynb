{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air_store dataframe shape: (829, 57)\n"
     ]
    }
   ],
   "source": [
    "from lib.preprocess import data_preparation\n",
    "df, train_size, test_size = data_preparation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size: (252108, 123) test data size: (32019, 123)\n"
     ]
    }
   ],
   "source": [
    "TARGET = 'visitors'\n",
    "\n",
    "visit_num_vars = ['dow', 'year', 'month', 'doy', 'dom', 'woy', 'is_month_end', 'date_int']\n",
    "\n",
    "reserve_num_vars = ['reserve_ppl_count_air', 'reserve_tot_count_air', 'avg_reserve_hr_day_air',\n",
    "    'max_reserve_hr_air', 'min_reserve_hr_air', 'mean_reserve_hr_air', 'min_reserve_dy_air',\n",
    "    'mean_reserve_dy_air', 'max_reserve_dy_air', 'reserve_ppl_count_hpg', 'reserve_tot_count_hpg',\n",
    "    'avg_reserve_hr_day_hpg', 'max_reserve_hr_hpg', 'min_reserve_hr_hpg', 'mean_reserve_hr_hpg',\n",
    "     'min_reserve_dy_hpg', 'mean_reserve_dy_hpg', 'max_reserve_dy_hpg']\n",
    "\n",
    "store_num_vars = [\n",
    "    'latitude_air', 'longitude_air', 'air_stores_on_same_addr', 'air_stores_lv1',\n",
    "    'air_stores_lv2', 'air_stores_lv3', 'mean_lat_air_lv1', 'max_lat_air_lv1',\n",
    "    'min_lat_air_lv1', 'mean_lon_air_lv1', 'max_lon_air_lv1', 'min_lon_air_lv1',\n",
    "    'mean_lat_air_lv2',  'max_lat_air_lv2', 'min_lat_air_lv2', 'mean_lon_air_lv2',\n",
    "    'max_lon_air_lv2',   'min_lon_air_lv2', 'air_genre_count', 'air_genre_count_lv1',\n",
    "    'air_genre_count_lv2',   'air_genre_count_lv3', 'latitude_hpg', 'longitude_hpg',\n",
    "    'hpg_stores_on_same_addr', 'hpg_stores_lv1', 'hpg_stores_lv2', 'hpg_stores_lv3',\n",
    "    'mean_lat_hpg_lv1', 'max_lat_hpg_lv1', 'min_lat_hpg_lv1', 'mean_lon_hpg_lv1',\n",
    "    'max_lon_hpg_lv1', 'min_lon_hpg_lv1', 'mean_lat_hpg_lv2', 'max_lat_hpg_lv2',\n",
    "    'min_lat_hpg_lv2', 'mean_lon_hpg_lv2', 'max_lon_hpg_lv2', 'min_lon_hpg_lv2',\n",
    "    'hpg_genre_count', 'hpg_genre_count_lv1', 'hpg_genre_count_lv2', 'hpg_genre_count_lv3'\n",
    "    ]\n",
    "store_cat_vars = [\n",
    "    'air_genre_name', 'air_lv1', 'air_lv2', 'air_lv3', 'air_lv4',\n",
    "    'hpg_genre_name', 'hpg_lv1', 'hpg_lv2', 'hpg_lv3'\n",
    "]\n",
    "\n",
    "interacts_vars = [\n",
    "    'reserve_ppl_count', 'reserve_tot_count', 'reserve_ppl_mean', 'lon_plus_lat_air',\n",
    "    'lat_to_mean_lat_air_lv1', 'lat_to_max_lat_air_lv1', 'lat_to_min_lat_air_lv1',\n",
    "    'lon_to_mean_lon_air_lv1', 'lon_to_max_lon_air_lv1', 'lon_to_min_lon_air_lv1',\n",
    "    'lat_to_mean_lat_air_lv2', 'lat_to_max_lat_air_lv2', 'lat_to_min_lat_air_lv2',\n",
    "    'lon_to_mean_lon_air_lv2', 'lon_to_max_lon_air_lv2', 'lon_to_min_lon_air_lv2',\n",
    "    'lat_to_mean_lat_hpg_lv1', 'lat_to_max_lat_hpg_lv1', 'lat_to_min_lat_hpg_lv1',\n",
    "    'lon_to_mean_lon_hpg_lv1', 'lon_to_max_lon_hpg_lv1', 'lon_to_min_lon_hpg_lv1',\n",
    "    'lat_to_mean_lat_hpg_lv2', 'lat_to_max_lat_hpg_lv2', 'lat_to_min_lat_hpg_lv2',\n",
    "    'lon_to_mean_lon_hpg_lv2', 'lon_to_max_lon_hpg_lv2', 'lon_to_min_lon_hpg_lv2',  \n",
    "]\n",
    "\n",
    "hol_mix_vars = ['weight1', 'weight2', 'holiday_flg']\n",
    "\n",
    "target_agg_vars = ['mean_visitors', 'max_visitors', 'min_visitors', 'median_visitors', 'wmean_visitors']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "features = visit_num_vars + reserve_num_vars + store_num_vars + store_cat_vars + interacts_vars + hol_mix_vars + target_agg_vars\n",
    "\n",
    "train = df[:train_size]\n",
    "test = df[train_size:]\n",
    "y = df[:train_size][TARGET][:train_size].values\n",
    "IDs = df[train_size:][train_size:].id.values\n",
    "print ('train data size:', train.shape, 'test data size:', test.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(197315, 115) (31591, 115)\n"
     ]
    }
   ],
   "source": [
    "train_x = train[train['visit_date'].between('2016-04-01', '2017-03-09')][features].values\n",
    "train_y = np.log1p(train[train['visit_date'].between('2016-04-01', '2017-03-09')][TARGET].values)\n",
    "\n",
    "valid_x = train[train['visit_date'] > '2017-03-09'][features].values\n",
    "valid_y = np.log1p(train[train['visit_date'] > '2017-03-09'][TARGET].values)\n",
    "print (train_x.shape, valid_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'eta': 0.1, 'gamma': 1, 'max_depth': 10, 'min_child_weight': 3, 'nthread': 8, 'objective': 'reg:linear', 'seed': 1, 'subsample': 1}\n",
      "[0]\ttrain-rmse:2.19653\teval-rmse:2.25204\n",
      "Multiple eval metrics have been passed: 'eval-rmse' will be used for early stopping.\n",
      "\n",
      "Will train until eval-rmse hasn't improved in 50 rounds.\n",
      "[100]\ttrain-rmse:0.440243\teval-rmse:0.484031\n",
      "[200]\ttrain-rmse:0.431116\teval-rmse:0.483825\n",
      "Stopping. Best iteration:\n",
      "[179]\ttrain-rmse:0.433678\teval-rmse:0.483671\n",
      "\n",
      "best_score: 0.483671, best_iteration: 179\n"
     ]
    }
   ],
   "source": [
    "xgtrain = xgb.DMatrix(train_x, label=train_y)\n",
    "xgval=xgb.DMatrix(valid_x,label=valid_y)\n",
    "\n",
    "watchlist  = [ (xgtrain,'train'),(xgval,'eval')]\n",
    "\n",
    "\n",
    "best_xgb_params = {'colsample_bytree': 0.7,\n",
    " 'eta': 0.1,\n",
    " 'gamma': 1,\n",
    " 'max_depth': 10,\n",
    " 'min_child_weight': 3,\n",
    " 'nthread': 8,\n",
    " 'objective': 'reg:linear',\n",
    " 'seed': 1,\n",
    " 'subsample': 1}\n",
    "\n",
    "print (best_xgb_params)\n",
    "\n",
    "model = xgb.train(best_xgb_params, \n",
    "                  xgtrain, \n",
    "                  num_boost_round=100000,\n",
    "                  evals=watchlist,\n",
    "                  early_stopping_rounds=50,\n",
    "                  verbose_eval=100)    \n",
    "best_iteration = model.best_iteration\n",
    "best_score = model.best_score\n",
    "print ('best_score: %f, best_iteration: %d' % (best_score, best_iteration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I:\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "I:\\Anaconda2\\envs\\py36\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(best_xgb_params, \n",
    "                  xgb.DMatrix(train_x, label=train_y), \n",
    "                  num_boost_round=best_iteration)  \n",
    "sub = test[['id','visitors']].copy()\n",
    "sub['visitors'] = model.predict(xgb.DMatrix(test[features].values))\n",
    "sub['visitors'] = np.expm1(sub['visitors']).clip(lower=0.)\n",
    "sub[['id', 'visitors']].to_csv('../submission/sub_starter.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
